import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.metrics import accuracy_score

# Load data
train = pd.read_csv('/kaggle/input/summer-analytics-mid-hackathon/hacktrain.csv')
test = pd.read_csv('/kaggle/input/summer-analytics-mid-hackathon/hacktest.csv')

def sort_ndvi_columns(df):
    ndvi_cols = [col for col in df.columns if '_N' in col]
    return sorted(ndvi_cols, key=lambda x: datetime.strptime(x.split('_')[0], "%Y%m%d"))

sorted_cols = sort_ndvi_columns(train)

def temporal_pipeline(df):
    df_ndvi = df[sorted_cols]

    df_interp = df_ndvi.interpolate(axis=1, method='linear', limit_direction='both')

    window_size = 3
    df_smoothed = df_interp.T.rolling(window=window_size, min_periods=1, center=True).mean().T
    return df_smoothed

train_clean = temporal_pipeline(train)
test_clean = temporal_pipeline(test)
def safe_slope(x):
    valid_mask = ~x.isna()
    if valid_mask.sum() < 2:
        return 0.0
    x_clean = x[valid_mask]
    return np.polyfit(np.arange(len(x_clean)), x_clean, 1)[0]

def extract_features(df):
    features = pd.DataFrame()
    features['annual_mean'] = df.mean(axis=1)
    features['annual_std'] = df.std(axis=1)
    features['annual_amplitude'] = df.max(axis=1) - df.min(axis=1)
    features['max_ndvi'] = df.max(axis=1)
    features['min_ndvi'] = df.min(axis=1)
    features['median_ndvi'] = df.median(axis=1)
    features['skew'] = df.skew(axis=1)
    features['kurtosis'] = df.kurtosis(axis=1)
    features['iqr'] = df.quantile(0.75, axis=1) - df.quantile(0.25, axis=1)
    
    seasons = {
        'winter': [12, 1, 2],
        'spring': [3, 4, 5],
        'summer': [6, 7, 8],
        'autumn': [9, 10, 11]
    }
    for season, months in seasons.items():
        cols = [col for col in df.columns 
                if datetime.strptime(col.split('_')[0], "%Y%m%d").month in months]
        features[f'{season}_mean'] = df[cols].mean(axis=1)
        features[f'{season}_std'] = df[cols].std(axis=1)
    
    features['slope'] = df.apply(safe_slope, axis=1)
    features['num_peaks'] = df.apply(lambda x: len(np.where(np.diff(np.sign(np.diff(x))) < 0)[0]), axis=1)
    return features

X_train = extract_features(train_clean)
X_test = extract_features(test_clean)

le = LabelEncoder()
y_train = le.fit_transform(train['class'])

pipeline = make_pipeline(
    StandardScaler(),
    LogisticRegression(
        multi_class='multinomial',
        solver='lbfgs',
        max_iter=2000,
        class_weight='balanced',
        random_state=42
    )
)

param_grid = {
    'logisticregression__C': [0.01, 0.1, 1, 10, 100],
    'logisticregression__penalty': ['l2']
}

grid = GridSearchCV(
    pipeline,
    param_grid,
    cv=5,
    scoring='accuracy',
    n_jobs=-1
)

grid.fit(X_train, y_train)

print("Best parameters:", grid.best_params_)
print("Best cross-validation accuracy:", grid.best_score_)


best_model = grid.best_estimator_
test_pred = le.inverse_transform(best_model.predict(X_test))

submission = pd.DataFrame({
    'ID': test['ID'],
    'class': test_pred
})
submission.to_csv('submission.csv', index=False)